{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sappw1/Dissertation/blob/main/Notebooks/Notebooks-Working/ETL/prac_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NLP + matching tools\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from rapidfuzz import process, fuzz\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")  # Optionally 'en_core_web_trf' for better accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loaded 2523 press releases.\n"
          ]
        }
      ],
      "source": [
        "# Load press releases (PRAC/DOJ reports)\n",
        "with open(\"Data/Raw/pandemic_reports.json\", encoding=\"utf-8\") as file:\n",
        "    press_releases = json.load(file)\n",
        "\n",
        "print(f\" Loaded {len(press_releases)} press releases.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned PPP loan data (from your earlier pipeline)\n",
        "loan_df = pd.read_csv(\"Data/Cleaned/clean_ppp_loans22apr25.csv\")\n",
        "\n",
        "# Ensure borrower names are normalized\n",
        "loan_df[\"normalized_borrowername\"] = loan_df[\"borrowername\"].str.lower().str.replace(\".\", \"\").str.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Improved regex for monetary values\n",
        "MONEY_REGEX = r\"\\$[\\d,.]+(?:\\s?(million|billion|thousand|k|m|b))?\"\n",
        "\n",
        "def parse_money(amount_str):\n",
        "    multipliers = {'thousand':1e3, 'million':1e6, 'billion':1e9, 'k':1e3, 'm':1e6, 'b':1e9}\n",
        "    amount_str = amount_str.lower().replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
        "    match = re.match(r\"([\\d.]+)\\s?(thousand|million|billion|k|m|b)?\", amount_str)\n",
        "    if match:\n",
        "        number = float(match.group(1))\n",
        "        multiplier = multipliers.get(match.group(2), 1)\n",
        "        return number * multiplier\n",
        "    return None\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    orgs = {ent.text.strip() for ent in doc.ents if ent.label_ == \"ORG\"}\n",
        "    people = {ent.text.strip() for ent in doc.ents if ent.label_ == \"PERSON\"}\n",
        "    locations = {ent.text.strip() for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]}\n",
        "    dates = {ent.text.strip() for ent in doc.ents if ent.label_ == \"DATE\" and re.search(r\"\\d{4}\", ent.text)}\n",
        "    money_mentions = {ent.text.strip() for ent in doc.ents if ent.label_ == \"MONEY\"}\n",
        "\n",
        "    money_from_regex = re.findall(MONEY_REGEX, text)\n",
        "    parsed_money = [parse_money(m[0] if isinstance(m, tuple) else m) for m in money_from_regex]\n",
        "    parsed_money = [amt for amt in parsed_money if amt]\n",
        "\n",
        "    return {\n",
        "        \"orgs\": list(orgs),\n",
        "        \"people\": list(people),\n",
        "        \"locations\": list(locations),\n",
        "        \"dates\": list(dates),\n",
        "        \"money_raw\": list(money_mentions),\n",
        "        \"loan_amounts\": parsed_money\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def match_press_release_to_loans(entities, loan_df, top_n=3, score_threshold=85, amount_tolerance=1000):\n",
        "    matches = []\n",
        "    name_pool = loan_df[\"normalized_borrowername\"].tolist()\n",
        "\n",
        "    for name in entities[\"orgs\"] + entities[\"people\"]:\n",
        "        top_matches = process.extract(name.lower(), name_pool, scorer=fuzz.token_sort_ratio, limit=top_n)\n",
        "        for match_name, score, idx in top_matches:\n",
        "            if score < score_threshold:\n",
        "                continue\n",
        "            loan_candidate = loan_df.iloc[idx]\n",
        "            for amount in entities[\"loan_amounts\"]:\n",
        "                if abs(amount - loan_candidate[\"currentapprovalamount\"]) < amount_tolerance:\n",
        "                    matches.append({\n",
        "                        \"MatchedLoanNumber\": loan_candidate[\"loannumber\"],\n",
        "                        \"MatchedBorrowerName\": loan_candidate[\"borrowername\"],\n",
        "                        \"LoanAmount\": loan_candidate[\"currentapprovalamount\"],\n",
        "                        \"LoanApprovalDate\": loan_candidate[\"dateapproved\"],\n",
        "                        \"MatchScore\": score,\n",
        "                        \"AmountDifference\": abs(amount - loan_candidate[\"currentapprovalamount\"])\n",
        "                    })\n",
        "    return matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|██████▊                                                                      | 222/2523 [52:38<9:11:11, 14.37s/it]"
          ]
        }
      ],
      "source": [
        "matched_results = []\n",
        "\n",
        "for release in tqdm(press_releases):\n",
        "    content = release.get(\"press_release\", \"\")\n",
        "    entities = extract_entities(content)\n",
        "    matches = match_press_release_to_loans(entities, loan_df)\n",
        "\n",
        "    for match in matches:\n",
        "        result = {\n",
        "            \"Title\": release.get(\"title\"),\n",
        "            \"Date\": release.get(\"date\"),\n",
        "            \"Link\": release.get(\"link\"),\n",
        "            **match,\n",
        "            \"is_fraudulent\": 1\n",
        "        }\n",
        "        matched_results.append(result)\n",
        "\n",
        "print(f\"\\n Total matched fraud cases: {len(matched_results)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "matched_df = pd.DataFrame(matched_results)\n",
        "matched_df.to_csv(\"Data/Processed/matched_fraud_cases.csv\", index=False)\n",
        "matched_df.to_json(\"Data/Processed/matched_fraud_cases.json\", orient=\"records\", indent=2)\n",
        "\n",
        "print(\" Matched fraud cases saved.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOR0Hs4wIMeftxpm6095Zt2",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
