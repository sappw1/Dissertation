{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR0Hs4wIMeftxpm6095Zt2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sappw1/Dissertation/blob/main/Notebooks/Notebooks-Working/ETL/prac_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Ty9rKiK3eD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "from rapidfuzz import fuzz, process\n",
        "import json\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Improved regex for monetary amounts\n",
        "MONEY_REGEX = r\"\\$[\\d,.]+(?:\\s?(million|billion|thousand|k|m|b))?\"\n",
        "\n",
        "def normalize_entity(entity):\n",
        "    if isinstance(entity, str):\n",
        "        entity = entity.lower().replace(\".\", \"\").strip()\n",
        "        entity = re.sub(r\"\\s+(llc|inc|corp|ltd)\\.?$\", \"\", entity)\n",
        "    else:\n",
        "        entity = \"\"\n",
        "    return entity\n",
        "\n",
        "def parse_money(amount_str):\n",
        "    multipliers = {'thousand':1e3, 'million':1e6, 'billion':1e9, 'k':1e3, 'm':1e6, 'b':1e9}\n",
        "    amount_str = amount_str.lower().replace(\",\", \"\").replace(\"$\", \"\").strip()\n",
        "    match = re.match(r\"([\\d.]+)\\s?(thousand|million|billion|k|m|b)?\", amount_str)\n",
        "    if match:\n",
        "        number = float(match.group(1))\n",
        "        multiplier = multipliers.get(match.group(2), 1)\n",
        "        return number * multiplier\n",
        "    return None\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = {\n",
        "        \"names\": list({normalize_entity(ent.text) for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\"]}),\n",
        "        \"locations\": list({ent.text for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]}),\n",
        "        \"dates\": list({ent.text for ent in doc.ents if ent.label_ == \"DATE\" and re.search(r\"\\d{4}\", ent.text)}),\n",
        "        \"money\": list({ent.text for ent in doc.ents if ent.label_ == \"MONEY\"})\n",
        "    }\n",
        "    loan_amounts = re.findall(MONEY_REGEX, text)\n",
        "    entities[\"loan_amounts\"] = [parse_money(amt[0] if isinstance(amt, tuple) else amt) for amt in loan_amounts]\n",
        "    entities[\"loan_amounts\"] = [amt for amt in entities[\"loan_amounts\"] if amt]\n",
        "    return entities\n",
        "\n",
        "# Load press releases from JSON\n",
        "with open(\"/content/drive/MyDrive/NCU/Dissertation/Data/pandemic_reports.json\", \"r\") as file:\n",
        "    press_releases = json.load(file)\n",
        "\n",
        "# Load loan applications data\n",
        "loan_df = pd.read_csv(\"/content/drive/MyDrive/NCU/Dissertation/Data/PPP_Loan_apps.csv\")\n",
        "loan_df[\"NormalizedBorrowerName\"] = loan_df[\"BorrowerName\"].apply(normalize_entity)\n",
        "\n",
        "matched_results = []\n",
        "\n",
        "for release in press_releases:\n",
        "    content = release[\"press_release\"]\n",
        "    entities = extract_entities(content)\n",
        "\n",
        "    matched_app = None\n",
        "\n",
        "    for name in entities[\"names\"]:\n",
        "        match_name, score, idx = process.extractOne(name, loan_df[\"NormalizedBorrowerName\"], scorer=fuzz.token_sort_ratio)\n",
        "        if score >= 85:\n",
        "            potential_match = loan_df.iloc[idx]\n",
        "\n",
        "            # Loan amount matching\n",
        "            amount_matched = False\n",
        "            for amount in entities[\"loan_amounts\"]:\n",
        "                if abs(amount - potential_match[\"CurrentApprovalAmount\"]) < 1000:\n",
        "                    amount_matched = True\n",
        "                    break\n",
        "\n",
        "            if amount_matched:\n",
        "                matched_app = potential_match\n",
        "                break\n",
        "\n",
        "    if matched_app is not None:\n",
        "        result = {\n",
        "            \"Title\": release[\"title\"],\n",
        "            \"Date\": release[\"date\"],\n",
        "            \"Link\": release[\"link\"],\n",
        "            \"MatchedLoanNumber\": matched_app[\"LoanNumber\"],\n",
        "            \"MatchedBorrowerName\": matched_app[\"BorrowerName\"],\n",
        "            \"LoanAmount\": matched_app[\"CurrentApprovalAmount\"],\n",
        "            \"LoanApprovalDate\": matched_app[\"DateApproved\"],\n",
        "            \"is_fraudulent\": 1\n",
        "        }\n",
        "        matched_results.append(result)\n",
        "\n",
        "# Save matched results\n",
        "matched_df = pd.DataFrame(matched_results)\n",
        "matched_df.to_csv(\"content/drive/MyDrive/NCU/Dissertation/Data/matched_fraud_cases_22mar25.csv\", index=False)\n",
        "matched_df.to_json(\"content/drive/MyDrive/NCU/Dissertation/Data/matched_fraud_cases_22mar25.json\", orient=\"records\", indent=4)\n",
        "\n",
        "print(f\"Matched {len(matched_results)} fraud cases saved.\")\n"
      ]
    }
  ]
}