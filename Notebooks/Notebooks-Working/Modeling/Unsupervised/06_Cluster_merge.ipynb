{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1fSFG7lLPZo98FvhlpNel",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sappw1/Dissertation/blob/main/Notebooks/Working/Modeling/06_Cluster_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z4jz103oRUo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === CONFIGURATION === #\n",
        "base_dir = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/Clustering\"\n",
        "kmeans_dir = os.path.join(base_dir, \"KMeans\")\n",
        "hier_dir = os.path.join(base_dir, \"Hierarchical\")\n",
        "dbscan_dir = os.path.join(base_dir, \"DBSCAN\")\n",
        "output_dir = os.path.join(base_dir, \"OptionC_Merged\")\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "oumxf3ZHoc3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature inclusion config\n",
        "config = {\n",
        "    \"use_kmeans\": True,\n",
        "    \"use_hier\": True,\n",
        "    \"use_dbscan\": True\n",
        "}"
      ],
      "metadata": {
        "id": "SV5vkOBtofEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load Base Features and Labels === #\n",
        "X_scaled = pd.read_csv(os.path.join(base_dir, \"X_all_scaled.csv\"), index_col=0)\n",
        "fraud_labels = pd.read_pickle(os.path.join(base_dir, \"y_labels.pkl\"))\n",
        "indices = pd.read_csv(os.path.join(base_dir, \"index_all_scaled.csv\"), index_col=0).index\n",
        "\n",
        "X_scaled = X_scaled.loc[indices]\n",
        "fraud_labels = fraud_labels.loc[indices]"
      ],
      "metadata": {
        "id": "2sqA7Kazogm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Initialize final DataFrame === #\n",
        "df = X_scaled.copy()\n",
        "df[\"fraud_label\"] = fraud_labels"
      ],
      "metadata": {
        "id": "9eyWxLPxoj9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Merge K-Means Clusters === #\n",
        "if config[\"use_kmeans\"]:\n",
        "    try:\n",
        "        kmeans_labels = np.load(os.path.join(kmeans_dir, \"labels_kmeans_Full_2C.npy\"))\n",
        "        if len(kmeans_labels) != len(df):\n",
        "            raise ValueError(\"Length mismatch in K-Means labels.\")\n",
        "        df[\"kmeans_cluster\"] = kmeans_labels\n",
        "        print(f\" K-Means cluster labels added.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading K-Means labels: {e}\")"
      ],
      "metadata": {
        "id": "f98in6Ngol9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Merge Hierarchical Clusters === #\n",
        "if config[\"use_hier\"]:\n",
        "    try:\n",
        "        hier_labels = np.load(os.path.join(hier_dir, \"labels_hier_Full_2C.npy\"))\n",
        "        if len(hier_labels) != len(df):\n",
        "            raise ValueError(\"Length mismatch in Hierarchical labels.\")\n",
        "        df[\"hier_cluster\"] = hier_labels\n",
        "        print(f\" Hierarchical cluster labels added.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading Hierarchical labels: {e}\")"
      ],
      "metadata": {
        "id": "xcmOMOo9op30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Merge DBSCAN Noise Flags === #\n",
        "if config[\"use_dbscan\"]:\n",
        "    try:\n",
        "        eps_val = 1.0  # You can change this for other variants\n",
        "        eps_str = f\"{int(eps_val * 10):02d}\"\n",
        "        noise_path = os.path.join(dbscan_dir, \"NoiseIndices\", f\"noise_indices_Full_2C_eps{eps_str}.csv\")\n",
        "        noise_ids = pd.read_csv(noise_path, header=None)[0]\n",
        "        df[\"dbscan_noise\"] = 0\n",
        "        df.loc[noise_ids, \"dbscan_noise\"] = 1\n",
        "        print(f\" DBSCAN noise flags added (ε = {eps_val})\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error loading DBSCAN noise indices: {e}\")"
      ],
      "metadata": {
        "id": "WzNMUmM5otl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Export final dataset === #\n",
        "out_path_csv = os.path.join(output_dir, \"X_all_augmented_optionC.csv\")\n",
        "out_path_pkl = os.path.join(output_dir, \"X_all_augmented_optionC.pkl\")\n",
        "df.to_csv(out_path_csv)\n",
        "df.to_pickle(out_path_pkl)\n",
        "\n",
        "print(f\"\\n Final merged dataset saved to:\\n - {out_path_csv}\\n - {out_path_pkl}\")\n",
        "print(f\" Shape: {df.shape}\")"
      ],
      "metadata": {
        "id": "pG1aITgUo9T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\\begin{longtable}{p{3.2cm} p{5.5cm} p{3.5cm} p{5.5cm}}\n",
        "\\caption{Selected Clustering Outputs Integrated into the Supervised Learning Dataset} \\\\\n",
        "\\toprule\n",
        "\\textbf{Clustering Method} & \\textbf{Selected Output File} & \\textbf{Feature Name} & \\textbf{Rationale} \\\\\n",
        "\\midrule\n",
        "\\endfirsthead\n",
        "\\multicolumn{4}{l}{\\textit{(continued from previous page)}} \\\\\n",
        "\\toprule\n",
        "\\textbf{Clustering Method} & \\textbf{Selected Output File} & \\textbf{Feature Name} & \\textbf{Rationale} \\\\\n",
        "\\midrule\n",
        "\\endhead\n",
        "\\midrule\n",
        "\\multicolumn{4}{r}{\\textit{(continued on next page)}} \\\\\n",
        "\\endfoot\n",
        "\\bottomrule\n",
        "\\endlastfoot\n",
        "\n",
        "K-Means & \\texttt{labels\\_kmeans\\_Full\\_2C.npy} & \\texttt{kmeans\\_cluster} & Highest silhouette score among K-Means configurations; interpretable two-cluster structure. \\\\\n",
        "\n",
        "Hierarchical & \\texttt{labels\\_hier\\_Full\\_2C.npy} & \\texttt{hier\\_cluster} & Strongest overall clustering metrics (Silhouette = 0.92, DBI = 0.056); observable fraud density in cluster groupings. \\\\\n",
        "\n",
        "DBSCAN & \\texttt{noise\\_indices\\_Full\\_2C\\_eps10.csv} & \\texttt{dbscan\\_noise} & High fraud concentration in noise cluster; ε = 1.0 offered optimal balance of separation and anomaly coverage. \\\\\n",
        "\n",
        "\\end{longtable}\n"
      ],
      "metadata": {
        "id": "-QI2u6cXxIm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4ZcyLozzxJlG"
      }
    }
  ]
}