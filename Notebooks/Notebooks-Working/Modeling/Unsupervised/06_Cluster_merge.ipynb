{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sappw1/Dissertation/blob/main/Notebooks/Working/Modeling/06_Cluster_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14674,"status":"ok","timestamp":1747688229575,"user":{"displayName":"William Sapp","userId":"00801756529197705217"},"user_tz":240},"id":"ZPNrnIoYvGdd","outputId":"a9ef9e96-57b0-4ef1-a971-508d2c9a71ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1747688230690,"user":{"displayName":"William Sapp","userId":"00801756529197705217"},"user_tz":240},"id":"2Z4jz103oRUo"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oumxf3ZHoc3S"},"outputs":[],"source":["\\begin{longtable}{p{3.2cm} p{5.5cm} p{3.5cm} p{5.5cm}}\n","\\caption{Selected Clustering Outputs Integrated into the Supervised Learning Dataset} \\\\\n","\\toprule\n","\\textbf{Clustering Method} & \\textbf{Selected Output File} & \\textbf{Feature Name} & \\textbf{Rationale} \\\\\n","\\midrule\n","\\endfirsthead\n","\\multicolumn{4}{l}{\\textit{(continued from previous page)}} \\\\\n","\\toprule\n","\\textbf{Clustering Method} & \\textbf{Selected Output File} & \\textbf{Feature Name} & \\textbf{Rationale} \\\\\n","\\midrule\n","\\endhead\n","\\midrule\n","\\multicolumn{4}{r}{\\textit{(continued on next page)}} \\\\\n","\\endfoot\n","\\bottomrule\n","\\endlastfoot\n","\n","K-Means & \\texttt{labels\\_kmeans\\_Full\\_2C.npy} & \\texttt{kmeans\\_cluster} & Highest silhouette score among K-Means configurations; interpretable two-cluster structure. \\\\\n","\n","Hierarchical & \\texttt{labels\\_hier\\_Full\\_2C.npy} & \\texttt{hier\\_cluster} & Strongest overall clustering metrics (Silhouette = 0.92, DBI = 0.056); observable fraud density in cluster groupings. \\\\\n","\n","DBSCAN & \\texttt{noise\\_indices\\_Full\\_3C\\_eps10.csv} & \\texttt{dbscan\\_noise} & High fraud concentration in noise cluster; ε = 1.0 offered optimal balance of separation and anomaly coverage. \\\\\n","\n","\\end{longtable}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SV5vkOBtofEj"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","# === CONFIGURATION === #\n","base_dir = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed\"\n","cluster_dir = os.path.join(base_dir, \"Clustering\")\n","output_dir = os.path.join(base_dir, \"cluster_features\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Index reference\n","index_all = pd.read_csv(os.path.join(cluster_dir, \"index_all_scaled.csv\"), index_col=0).index\n","\n","# === CLUSTER FEATURE DEFINITIONS === #\n","cluster_configs = [\n","    {\n","        \"source_file\": os.path.join(cluster_dir, \"KMeans\", \"labels_Full_(2C)_k2.npy\"),\n","        \"column_name\": \"kmeans_full2c_ordinal\",\n","        \"type\": \"ordinal\"\n","    },\n","    {\n","        \"source_file\": os.path.join(cluster_dir, \"Hierarchical\", \"labels_hier_full_2c.npy\"),\n","        \"column_name\": \"hier_full2c_ordinal\",\n","        \"type\": \"ordinal\"\n","    },\n","    {\n","        \"source_file\": os.path.join(cluster_dir, \"DBSCAN\", \"NoiseIndices\", \"noise_indices_Key_3C_eps10.csv\"),\n","        \"column_name\": \"dbscan_key3c_e100_noise\",\n","        \"type\": \"binary\"\n","    }\n","]\n","\n","# === EXECUTION === #\n","for config in cluster_configs:\n","    path = config[\"source_file\"]\n","    col = config[\"column_name\"]\n","    col_type = config[\"type\"]\n","\n","    if not os.path.exists(path):\n","        print(f\" Missing: {path}\")\n","        continue\n","\n","    if col_type == \"ordinal\":\n","        labels = np.load(path)\n","        if len(labels) != len(index_all):\n","            print(f\"  Length mismatch in {col}: {len(labels)} vs {len(index_all)}\")\n","            continue\n","        feature_series = pd.Series(labels, index=index_all, name=col)\n","\n","    elif col_type == \"binary\":\n","        noise_ids = pd.read_csv(path, header=None)[0].astype(str)\n","        binary_series = pd.Series(0, index=index_all, name=col)\n","        binary_series.loc[binary_series.index.isin(noise_ids)] = 1\n","        feature_series = binary_series\n","\n","    else:\n","        print(f\"  Unknown type for {col}\")\n","        continue\n","\n","    # Save as DataFrame\n","    df_out = feature_series.to_frame()\n","    out_path = os.path.join(output_dir, f\"{col}.pkl\")\n","    df_out.to_pickle(out_path)\n","    print(f\" Saved: {out_path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sqA7Kazogm2"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# File paths\n","input_csv = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/ppp_loans_preprocessed.csv\"\n","output_path = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/X_all_scaled.pkl\"\n","\n","# Load and drop label\n","df = pd.read_csv(input_csv, index_col=0)\n","X = df.drop(columns=[\"is_fraudulent\"])\n","\n","# Save features only\n","X.to_pickle(output_path)\n","\n","print(f\" Saved: {output_path}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6404,"status":"ok","timestamp":1747682597671,"user":{"displayName":"William Sapp","userId":"00801756529197705217"},"user_tz":240},"id":"244Wq8A_vcQX","outputId":"dd373d22-d05f-4107-f02f-6631139395dc"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Saved: /content/drive/MyDrive/NCU/Dissertation/Data/Processed/X_all_scaled.pkl\n"]}],"source":["import pandas as pd\n","import os\n","\n","# File paths\n","input_pkl = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/ppp_loans_preprocessed_cleaned.pkl\"\n","output_path = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/X_all_scaled.pkl\"\n","\n","# Load and drop label\n","df = pd.read_pickle(input_pkl)\n","X = df.drop(columns=[\"is_fraudulent\"])\n","\n","# Save features only\n","X.to_pickle(output_path)\n","\n","print(f\" Saved: {output_path}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12230,"status":"ok","timestamp":1747690045408,"user":{"displayName":"William Sapp","userId":"00801756529197705217"},"user_tz":240},"id":"9eyWxLPxoj9e","outputId":"5b35685a-cab6-4be2-810c-a587d18ef801"},"outputs":[{"output_type":"stream","name":"stdout","text":[" Added: kmeans_full2c_ordinal\n"," Added: hier_full2c_ordinal\n"," Added: dbscan_key3c_e100_noise\n","\n"," Saved: /content/drive/MyDrive/NCU/Dissertation/Data/Processed/X_all_augmented.pkl\n"]}],"source":["import os\n","import pandas as pd\n","\n","# Define paths\n","base_dir = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed\"\n","cluster_dir = os.path.join(base_dir, \"Clustering\")\n","feature_dir = os.path.join(base_dir, \"cluster_features\")\n","os.makedirs(feature_dir, exist_ok=True)\n","\n","# Filenames\n","index_file = os.path.join(cluster_dir, \"index_all_scaled.csv\")\n","X_scaled_file = os.path.join(base_dir, \"X_all_scaled.pkl\")\n","\n","# Output\n","output_file = os.path.join(base_dir, \"X_all_augmented.pkl\")\n","\n","# Load index and master scaled dataset\n","index_all = pd.read_csv(index_file, index_col=0).index\n","X_all_scaled = pd.read_pickle(X_scaled_file)\n","X_all_scaled = X_all_scaled.loc[index_all]\n","\n","# Load cluster-based features\n","feature_files = {\n","    \"kmeans_full2c_ordinal\": os.path.join(feature_dir, \"kmeans_full2c_ordinal.pkl\"),\n","    \"hier_full2c_ordinal\": os.path.join(feature_dir, \"hier_full2c_ordinal.pkl\"),\n","    \"dbscan_key3c_e100_noise\": os.path.join(feature_dir, \"dbscan_key3c_e100_noise.pkl\")\n","}\n","\n","# Merge each cluster feature into X\n","for label, path in feature_files.items():\n","    if os.path.exists(path):\n","        cluster_col = pd.read_pickle(path)\n","        cluster_col.name = label\n","        X_all_scaled[label] = cluster_col\n","        print(f\" Added: {label}\")\n","    else:\n","        print(f\" Missing: {label} — Skipped.\")\n","\n","# Save augmented dataset\n","X_all_scaled.to_pickle(output_file)\n","print(f\"\\n Saved: {output_file}\")\n"]},{"cell_type":"markdown","metadata":{"id":"4ZcyLozzxJlG"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}