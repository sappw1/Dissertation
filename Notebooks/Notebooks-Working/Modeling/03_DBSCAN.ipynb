{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baab527-034b-44c6-8a9b-8231b50c72ef",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import pandas as pd\n",
    "import cudf\n",
    "from cuml import DBSCAN\n",
    "from cuml.metrics.cluster.silhouette_score import cython_silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b002441e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def run_dbscan_on_all(pca_data, output_dir, min_samples=5, eps_list=None):\n",
    "    if eps_list is None:\n",
    "        eps_list = [0.3, 0.5, 0.7, 1.0, 1.3]\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results = {}\n",
    "\n",
    "    for name, X in pca_data.items():\n",
    "        print(f\"\\n Running DBSCAN on: {name}\")\n",
    "        results[name] = {}\n",
    "        for eps in eps_list:\n",
    "            print(f\"  â€¢ eps = {eps}\")\n",
    "            model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = model.fit_predict(X).to_numpy()\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise = np.sum(labels == -1)\n",
    "\n",
    "            metrics = {\n",
    "                \"n_clusters\": int(n_clusters),\n",
    "                \"n_noise\": int(n_noise),\n",
    "                \"eps\": float(eps)\n",
    "            }\n",
    "\n",
    "            # Compute silhouette if more than 1 cluster and not all noise\n",
    "            if n_clusters > 1 and n_noise < len(labels):\n",
    "                try:\n",
    "                    sil = float(cython_silhouette_score(X, labels.get(), metric='euclidean'))\n",
    "                    dbi = davies_bouldin_score(X.to_numpy(), labels.get())\n",
    "                    metrics[\"silhouette\"] = float(sil)\n",
    "                    metrics[\"dbi\"] = float(dbi)\n",
    "                except Exception as e:\n",
    "                    print(f\"    (skipped metrics: {e})\")\n",
    "\n",
    "            # Save cluster labels\n",
    "            label_filename = f\"labels_dbscan_{name}_eps{str(eps).replace('.', '')}.npy\"\n",
    "            np.save(os.path.join(output_dir, label_filename), labels)\n",
    "\n",
    "            results[name][str(eps)] = metrics\n",
    "\n",
    "    # Save JSON\n",
    "    with open(os.path.join(output_dir, \"dbscan_results.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(\"\\n All DBSCAN runs complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6409893",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import cupy as cp\n",
    "import cudf\n",
    "\n",
    "#  Mount your Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#  Paths\n",
    "input_dir = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/PCA_Arrays\"\n",
    "output_dir = \"/content/drive/MyDrive/NCU/Dissertation/Data/Processed/Clustering/DBSCAN\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#  Load only the 2C and 3C PCA projections (95% skipped)\n",
    "X_all_pca_2 = cp.load(os.path.join(input_dir, \"X_all_pca_2.npy\"))\n",
    "X_all_pca_3 = cp.load(os.path.join(input_dir, \"X_all_pca_3.npy\"))\n",
    "X_key_pca_2 = cp.load(os.path.join(input_dir, \"X_key_pca_2.npy\"))\n",
    "X_key_pca_3 = cp.load(os.path.join(input_dir, \"X_key_pca_3.npy\"))\n",
    "\n",
    "print(\" Selected PCA arrays loaded for DBSCAN.\")\n",
    "\n",
    "# Convert CuPy arrays to cuDF DataFrames\n",
    "def to_cudf(cp_array):\n",
    "    return cudf.DataFrame(cp_array)\n",
    "\n",
    "#  Dictionary for DBSCAN\n",
    "dbscan_inputs = {\n",
    "    \"Full (2C)\": to_cudf(X_all_pca_2),\n",
    "    \"Full (3C)\": to_cudf(X_all_pca_3),\n",
    "    \"Key (2C)\": to_cudf(X_key_pca_2),\n",
    "    \"Key (3C)\": to_cudf(X_key_pca_3),\n",
    "}\n",
    "\n",
    "# Run DBSCAN clustering on all configs\n",
    "run_dbscan_on_all(dbscan_inputs, output_dir, min_samples=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
